{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e7c6f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from pathlib import Path\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import time\n",
    "import gensim\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re, string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b13cadb",
   "metadata": {},
   "source": [
    "Class orgainzing COCO data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a2f806",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# load COCO metadata\n",
    "filename = \"data/captions_train2014.json\"\n",
    "with Path(filename).open() as f:\n",
    "    coco_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68301e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class coco_values:\n",
    "    def __init__(self, coco_data):\n",
    "        self.coco_annotations = coco_data['annotations']\n",
    "        self.coco_images = coco_data['images']\n",
    "        self.coco_img_ids = [i['id'] for i in self.coco_images]\n",
    "        self.coco_cap_ids = [i['id'] for i in self.coco_annotations]\n",
    "    def get_captions(self, image_id):\n",
    "        return [i['id'] for i in self.coco_annotations if i['image_id'] == image_id]\n",
    "    def get_image_from_cap(self, caption_id):\n",
    "        return [i['image_id'] for i in self.coco_annotations if i['id'] == caption_id][0]\n",
    "    def get_caption_text(self, caption_id):\n",
    "        return [i['caption'] for i in self.coco_annotations if i['id'] == caption_id][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629b0f1f",
   "metadata": {},
   "source": [
    "Embed caption:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705724e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load glove dataset\n",
    "path = r\"data/glove.6B.200d.txt.w2v\"\n",
    "t0 = time.time()\n",
    "glove = KeyedVectors.load_word2vec_format(path, binary=False)\n",
    "t1 = time.time()\n",
    "print(\"elapsed %ss\" % (t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69358ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string2vectors(given_str,IDF=None):\n",
    "    if IDF is None:\n",
    "        print(\"No IDF given, loading GloVe-200d\")\n",
    "        path = r\"data/glove.6B.200d.txt.w2v\"\n",
    "        t0 = time.time()\n",
    "        IDF = KeyedVectors.load_word2vec_format(path, binary=False)\n",
    "        t1 = time.time()\n",
    "        print(\"GloVe loaded in: %ss\" % (t1-t0))\n",
    "    punc_regex = re.compile('[{}]'.format(re.escape(string.punctuation)))\n",
    "    given_str = punc_regex.sub('', given_str)\n",
    "    str_list = given_str.lower().split()\n",
    "    return [IDF[word] if word in IDF else np.zeroes((200,)) for word in str_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d54ed1",
   "metadata": {},
   "source": [
    "MyNN model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f972f4fa",
   "metadata": {},
   "source": [
    "Extract Sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87a15e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = coco_values.coco_img_ids\n",
    "pairs = []\n",
    "for image_id in image_ids:\n",
    "    caption_ids = coco_values.get_captions(image_id)\n",
    "    pairs.append(set(image_id, caption_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc538cd",
   "metadata": {},
   "source": [
    "Compute loss:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a684c6",
   "metadata": {},
   "source": [
    "Train the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9995a831",
   "metadata": {},
   "source": [
    "Saving /  loading weights:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d7d7a0",
   "metadata": {},
   "source": [
    "Generate image vectors:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c1e613",
   "metadata": {},
   "source": [
    "Create image database:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cee622",
   "metadata": {},
   "source": [
    "Query database:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d30946",
   "metadata": {},
   "source": [
    "Display images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fad59c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
