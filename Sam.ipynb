{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8259d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from pathlib import Path\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import time\n",
    "import gensim\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re, string\n",
    "import pickle\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41bff43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load COCO metadata\n",
    "filename = \"data/captions_train2014.json\"\n",
    "with Path(filename).open() as f:\n",
    "    coco_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d5d69a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder:\n",
    "    def __init__(self, model, idf):\n",
    "        self.model = model\n",
    "        self.idf = idf\n",
    "    def __call__(self, text):\n",
    "        x = sum(_get(self.model, w, 0.0) * self.idf.get(w, 0) for w in get_words(text))\n",
    "        return x / np.linalg.norm(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4dbb556f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class coco_values:\n",
    "    def __init__(self, coco_data):\n",
    "        #make variables for images and captions\n",
    "        self.coco_annotations = coco_data['annotations']\n",
    "        self.coco_images = coco_data['images']\n",
    "        self.coco_img_ids = [i['id'] for i in self.coco_images if i['id'] in resnet18_features.keys()]\n",
    "        self.coco_cap_ids = [i['id'] for i in self.coco_annotations if i['image_id'] in resnet18_features.keys()]\n",
    "        self.image2cap = {}\n",
    "                \n",
    "        for i in self.coco_annotations:\n",
    "            if i['image_id'] in self.image2cap.keys():\n",
    "                ids = self.image2cap[i['image_id']]\n",
    "                ids.append(i['id'])\n",
    "                self.image2cap[i['image_id']] = ids\n",
    "            else:\n",
    "                self.image2cap[i['image_id']] = [i['id']]\n",
    "        self.cap2image = {i['id']: i['image_id'] for i in self.coco_annotations}\n",
    "        self.cap2text = {i['id']: i['caption'] for i in self.coco_annotations}\n",
    "        self.image2url = {i['id']: i['coco_url'] for i in self.coco_images}\n",
    "        self.capID2embeded = None\n",
    "        self.captions = list(self.cap2text.values())\n",
    "    def get_captions(self, image_id):\n",
    "        #Find the caption IDs by returning all caption IDs associated with an image ID\n",
    "        return self.image2cap[image_id]\n",
    "    def get_image_from_cap(self, caption_id):\n",
    "        #Find the image ID by seeing if any image had a caption ID match\n",
    "        return self.cap2image[caption_id]\n",
    "    def get_caption_text(self, caption_id):\n",
    "        #Take the text from a given caption ID\n",
    "        return self.cap2text[caption_id]\n",
    "    def get_url(self, image_id):\n",
    "        return self.image2url[image_id]\n",
    "    def init_id2vec(self, model):\n",
    "        self.capID2embeded = {}\n",
    "        idf = inverse_doc_freq(self.captions)\n",
    "        self.text_embedder = Embedder(model,idf)\n",
    "        self.capID2embeded = {_id: self.text_embedder(self.get_caption_text(_id)) for _id in self.coco_cap_ids}\n",
    "\n",
    "    def compute_id2vec(self, caption_ids):\n",
    "        if self.capID2embeded is None:\n",
    "            print(\"No caption to embeded dictionary created! Run init_id2vec before running\")\n",
    "            return None\n",
    "        \n",
    "        if isinstance(caption_ids,int):\n",
    "            return np.array(self.capID2embeded[caption_ids])\n",
    "        else:\n",
    "            vectors = np.zeros((len(caption_ids), 200), dtype=np.int32)\n",
    "            for n, _id in enumerate(caption_ids):\n",
    "                vectors[n] = self.capID2embeded[_id]\n",
    "            return vectors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbdaf6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "punc_regex = re.compile('[{}]'.format(re.escape(string.punctuation)))\n",
    "def comp_inverse_doc_freq(documents):\n",
    "    df = Counter()\n",
    "    for doc in documents:\n",
    "        df.update(set(get_words(doc)))\n",
    "    return df\n",
    "def inverse_doc_freq(documents):\n",
    "    df = comp_inverse_doc_freq(documents)\n",
    "    return {word: np.log10(len(documents) / count) for word, count in df.items()}\n",
    "def get_words(text):\n",
    "    return punc_regex.sub('', text.lower()).split()\n",
    "def _get(model, k, value = None, verbose = None):\n",
    "    try:\n",
    "        return model[k]\n",
    "    except KeyError:\n",
    "        if verbose:\n",
    "            print(f\"'(k)' is not in the word-embedding vocabulary\")\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8137f856",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Path('data/resnet18_features.pkl').open('rb') as f:\n",
    "    resnet18_features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ebfefef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = coco_values(coco_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0797675d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[48, 126, 219, 255, 3555]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.get_captions(318556)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4775a6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318556"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.get_image_from_cap(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc2e432c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A very clean and well decorated empty bathroom'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.get_caption_text(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efcd1e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed 68.24052047729492s\n"
     ]
    }
   ],
   "source": [
    "#load glove dataset\n",
    "path = r\"data/glove.6B.200d.txt.w2v\"\n",
    "t0 = time.time()\n",
    "glove = KeyedVectors.load_word2vec_format(path, binary=False)\n",
    "t1 = time.time()\n",
    "print(\"elapsed %ss\" % (t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5808d94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.init_id2vec(glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6ae3ac3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.07061214, -0.02274254, -0.00940832, -0.04032666, -0.03778504,\n",
       "       -0.00521474, -0.04675333,  0.03444962,  0.02304072, -0.02254693,\n",
       "        0.01115278,  0.04039143,  0.015667  ,  0.02873464,  0.06777503,\n",
       "        0.03655904, -0.04502166,  0.04222867,  0.06746073, -0.05405859,\n",
       "        0.03160565,  0.4979816 ,  0.08423478, -0.05645183,  0.06801857,\n",
       "       -0.1470793 , -0.01028187, -0.0760544 , -0.07318673, -0.05556216,\n",
       "        0.02297116, -0.02974771,  0.06205539,  0.03704238, -0.03858265,\n",
       "       -0.0183256 , -0.04962338, -0.07829404,  0.07678512,  0.01260141,\n",
       "        0.01075453,  0.06749362, -0.00623134,  0.06552903, -0.02075985,\n",
       "       -0.01964161,  0.1442396 , -0.04593186, -0.00131347,  0.07078432,\n",
       "        0.01679406,  0.06363841, -0.0230912 ,  0.08268034,  0.01778664,\n",
       "       -0.01112581, -0.01539579, -0.06673906, -0.08046044, -0.01877393,\n",
       "        0.005516  ,  0.03242494, -0.06550016,  0.0571154 , -0.03657656,\n",
       "        0.05755676, -0.02064952, -0.05495303, -0.00078629, -0.05866395,\n",
       "        0.10014598, -0.02797203, -0.04314916,  0.0291264 , -0.05516198,\n",
       "       -0.00797034, -0.1139975 , -0.09418847, -0.07856473, -0.0180107 ,\n",
       "       -0.01649904, -0.05417265, -0.01754106,  0.06027613,  0.13241455,\n",
       "       -0.00796594,  0.12390073, -0.06980538,  0.12579489, -0.19905038,\n",
       "        0.00149774,  0.01036998,  0.01958021,  0.01714805, -0.01370455,\n",
       "        0.00138472,  0.04715524, -0.0267098 , -0.07967622,  0.05670698,\n",
       "        0.05677124, -0.03910695, -0.01499234,  0.01531284,  0.05661622,\n",
       "       -0.03836191,  0.02183072,  0.20086503, -0.05762524,  0.04741119,\n",
       "       -0.02285038, -0.04813251,  0.02322656,  0.02108136, -0.05890768,\n",
       "       -0.04324944,  0.07642899,  0.02894655, -0.05058524, -0.01685672,\n",
       "        0.07082385,  0.04476399,  0.04825117, -0.02736553,  0.00470138,\n",
       "       -0.1571474 ,  0.07964221,  0.03203056,  0.07222462, -0.01433841,\n",
       "        0.07491538,  0.00956063,  0.05258132, -0.15121211, -0.01613061,\n",
       "        0.00240515,  0.00415333, -0.0084056 , -0.01775461, -0.03848843,\n",
       "        0.0561331 , -0.02880432,  0.07049616,  0.01120092,  0.22053708,\n",
       "        0.09974126, -0.01220535, -0.01605374,  0.01820368, -0.02122691,\n",
       "        0.02380499, -0.02307396,  0.0674959 , -0.05763737,  0.05490159,\n",
       "       -0.08663332, -0.07067514,  0.02787291,  0.02911703, -0.03913857,\n",
       "        0.03771986,  0.03372729, -0.00264036,  0.0498387 ,  0.01462482,\n",
       "       -0.01580716, -0.01998619,  0.02818731, -0.14279328,  0.05120087,\n",
       "       -0.06277992, -0.01690063,  0.00833087,  0.10717661, -0.01086863,\n",
       "       -0.02272646, -0.0934496 , -0.05806227, -0.00265982,  0.06422342,\n",
       "        0.21839346, -0.07412522, -0.07046547, -0.00738326,  0.01526242,\n",
       "        0.03378379, -0.04056406,  0.0046157 ,  0.03907179,  0.06489722,\n",
       "        0.01456817,  0.00546264, -0.046287  , -0.06654424,  0.09459667,\n",
       "        0.02436775, -0.04036422,  0.00322762, -0.05764424,  0.01451961],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.compute_id2vec(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "491884ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.compute_id2vec((48,48))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d95df2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageToWord:\n",
    "    \"\"\"A linear encoder network that produces normalized vectors\n",
    "    in the embedded space\"\"\"\n",
    "\n",
    "    def __init__(self, in_dim: int, out_dim: int):\n",
    "        self.dense = dense(\n",
    "            in_dim, out_dim, weight_initializer=glorot_normal, bias=False\n",
    "        )\n",
    "\n",
    "    def __call__(self, x: np.ndarray) -> mg.Tensor:\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : numpy.ndarray, shape-(N, C)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        mygrad.Tensor, shape-(N, D)\n",
    "            The normalized linear projection of each of the N data\n",
    "        \"\"\"\n",
    "        out = self.dense(x)\n",
    "        return out / mg.sqrt(mg.einsum(\"ij, ij -> i\", out, out)).reshape(-1, 1)\n",
    "\n",
    "    @property\n",
    "    def parameters(self) -> Tuple[mg.Tensor, ...]:\n",
    "        return self.dense.parameters\n",
    "\n",
    "    def save_model(self, path):\n",
    "        \"\"\"Path to .npz file where model parameters will be saved.\"\"\"\n",
    "        with open(path, \"wb\") as f:\n",
    "            np.savez(f, *(x.data for x in self.parameters))\n",
    "\n",
    "    def load_model(self, path):\n",
    "        with open(path, \"rb\") as f:\n",
    "            for param, (name, array) in zip(self.parameters, np.load(f).items()):\n",
    "                param.data[:] = array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d722b504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnetID2vectors(N,resnet_model=None):\n",
    "    if resnet_model is None:\n",
    "        print(\"no resnet model given, using ResNet18\")\n",
    "        with Path('data/resnet18_features.pkl').open('rb') as f:\n",
    "            resnet_model = pickle.load(f)\n",
    "    return [resnet_model[i] for i in N if i in resnet_model.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c09aa908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(image_ids, coco, num_good_captions: int, triples_per_caption: int = 10,tournment_size=25):\n",
    "    triples = []\n",
    "    for i in range(num_good_captions):\n",
    "        #getting good image\n",
    "        good_image_id = np.random.choice(image_ids)\n",
    "        \n",
    "        #getting caption\n",
    "        good_caption_id: int = np.random.choice(coco.get_captions(good_image_id))\n",
    "        good_caption_embedding = coco.compute_id2vec(good_caption_id)\n",
    "        for j in range(triples_per_caption):\n",
    "            bad_image_id = caption2badimage(good_caption_embedding, good_image_id, coco.coco_img_ids, coco, tournment_size)\n",
    "        \n",
    "            #add triples\n",
    "            triples.append((good_caption_id, good_image_id, bad_image_id))\n",
    "        \n",
    "    np.random.shuffle(triples)\n",
    "    \n",
    "    return triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e95758a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def caption2badimage(caption_embedding, good_image_id, possible_im_ids, coco, tournament_size):\n",
    "    best_score = -1.0\n",
    "    best_bad_img_id = -1\n",
    "    for _ in range(tournament_size):\n",
    "        bad_image_id = good_image_id\n",
    "        while bad_image_id == good_image_id: #choosing a distinct bad image id from the set of available \n",
    "            bad_image_id = np.random.choice(possible_im_ids)\n",
    "        \n",
    "        bad_caption_id = np.random.choice(coco.get_captions(bad_image_id))\n",
    "        bad_embedding = coco.compute_id2vec(bad_caption_id)\n",
    "        sim = np.matmul(caption_embedding,bad_embedding)\n",
    "        \n",
    "        if sim > best_score:\n",
    "            best_score = sim\n",
    "            best_bad_img_id = bad_image_id\n",
    "            \n",
    "    print(best_score)\n",
    "    return best_bad_img_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1b80110d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://images.cocodataset.org/train2014/COCO_train2014_000000571395.jpg\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "isinstance() arg 2 must be a type or tuple of types",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11680/3169427386.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mID\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoco_cap_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_image_from_cap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcaption2badimage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_id2vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_image_from_cap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoco_img_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11680/1348425978.py\u001b[0m in \u001b[0;36mcompute_id2vec\u001b[1;34m(self, caption_id)\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcaption_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapID2embeded\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcaption_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_id2vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcaption_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: isinstance() arg 2 must be a type or tuple of types"
     ]
    }
   ],
   "source": [
    "ID = -1\n",
    "while ID not in x.coco_cap_ids:\n",
    "    ID = int(np.random.choice(x.coco_cap_ids))\n",
    "print(x.get_url(x.get_image_from_cap(ID)))\n",
    "print(x.get_url(caption2badimage(x.compute_id2vec(ID), x.get_image_from_cap(ID),x.coco_img_ids, x,1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7feb472e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(716588, 303617, 36029),\n",
       " (666909, 559544, 230462),\n",
       " (49896, 431628, 74429),\n",
       " (64868, 244530, 113857),\n",
       " (374390, 265008, 24782),\n",
       " (829308, 181584, 558584),\n",
       " (490160, 266436, 525876),\n",
       " (407049, 557974, 190219),\n",
       " (525853, 42819, 187277),\n",
       " (746675, 482798, 77195)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_data(x.coco_img_ids, x, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
