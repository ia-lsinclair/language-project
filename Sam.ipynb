{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8259d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from pathlib import Path\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import time\n",
    "import gensim\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re, string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06d61a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load COCO metadata\n",
    "filename = \"data/captions_train2014.json\"\n",
    "with Path(filename).open() as f:\n",
    "    coco_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95fb7b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class coco_values:\n",
    "    def __init__(self, coco_data):\n",
    "        #make variables for images and captions\n",
    "        self.coco_annotations = coco_data['annotations']\n",
    "        self.coco_images = coco_data['images']\n",
    "        self.coco_img_ids = [i['id'] for i in self.coco_images]\n",
    "        self.coco_cap_ids = [i['id'] for i in self.coco_annotations]\n",
    "    def get_captions(self, image_id):\n",
    "            #Find the caption IDs by returning all caption IDs associated with an image ID\n",
    "        return [i['id'] for i in self.coco_annotations if i['image_id'] == image_id]\n",
    "    def get_image_from_cap(self, caption_id):\n",
    "        #Find the image ID by seeing if any image had a caption ID match\n",
    "        return [i['image_id'] for i in self.coco_annotations if i['id'] == caption_id][0]\n",
    "    def get_caption_text(self, caption_id):\n",
    "        #Take the text from a given caption ID\n",
    "        return [i['caption'] for i in self.coco_annotations if i['id'] == caption_id][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ebfefef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = coco_values(coco_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0797675d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[48, 126, 219, 255, 3555]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.get_captions(318556)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4775a6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318556"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.get_image_from_cap(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc2e432c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A very clean and well decorated empty bathroom'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.get_caption_text(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efcd1e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed 97.68171954154968s\n"
     ]
    }
   ],
   "source": [
    "#load glove dataset\n",
    "path = r\"data/glove.6B.200d.txt.w2v\"\n",
    "t0 = time.time()\n",
    "glove = KeyedVectors.load_word2vec_format(path, binary=False)\n",
    "t1 = time.time()\n",
    "print(\"elapsed %ss\" % (t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2498b95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string2vectors(given_str,IDF=None):\n",
    "    if IDF is None:\n",
    "        print(\"No IDF given, loading GloVe-200d\")\n",
    "        path = r\"data/glove.6B.200d.txt.w2v\"\n",
    "        t0 = time.time()\n",
    "        IDF = KeyedVectors.load_word2vec_format(path, binary=False)\n",
    "        t1 = time.time()\n",
    "        print(\"GloVe loaded in: %ss\" % (t1-t0))\n",
    "    punc_regex = re.compile('[{}]'.format(re.escape(string.punctuation)))\n",
    "    given_str = punc_regex.sub('', given_str)\n",
    "    str_list = given_str.lower().split()\n",
    "    return [IDF[word] if word in IDF else np.zeroes((200,)) for word in str_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0847d790",
   "metadata": {},
   "outputs": [],
   "source": [
    "#string2vectors(\"My dog loves me\",glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e6dc8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageToWord():\n",
    "    \"\"\"Implements a simple-cell RNN that produces both outputs and hidden descriptors.\"\"\"\n",
    "    def __init__(self, dim_input, dim_recurrent, dim_output):\n",
    "        \"\"\" Initializes all layers needed for RNN\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        dim_input: int \n",
    "            Dimensionality of data passed to RNN (C)\n",
    "        \n",
    "        dim_recurrent: int\n",
    "            Dimensionality of hidden state in RNN (D)\n",
    "        \n",
    "        dim_output: int\n",
    "            Dimensionality of output of RNN (K)\n",
    "        \"\"\"\n",
    "        # Initialize one dense layer for each matrix multiplication that appears\n",
    "        # in the simple-cell RNN equation; name these \"layers\" in ways that make\n",
    "        # their correspondence to the equation obvious\n",
    "\n",
    "        self.fc_x2h = dense(dim_input, dim_recurrent, weight_initializer=glorot_normal)\n",
    "        self.fc_h2h = dense(dim_recurrent, dim_recurrent, weight_initializer=glorot_normal, bias=False)\n",
    "        self.fc_h2y = dense(dim_recurrent, dim_output, weight_initializer=glorot_normal)\n",
    "\n",
    "    \n",
    "    \n",
    "    def __call__(self, x, h=None):\n",
    "        \"\"\" Performs the full forward pass for the RNN.\n",
    "        \n",
    "        Note that we will return the hidden states h_t and classification scores y_t for the\n",
    "        full sequence, even though our loss will only utilize the last y_T.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x: Union[numpy.ndarray, mygrad.Tensor], shape=(T, C)\n",
    "            The one-hot encodings for the sequence\n",
    "        \n",
    "        h: Optional[Union[numpy.ndarray, mygrad.Tensor]], shape=(1, D)\n",
    "            An optional initial hidden dimension state h_0.\n",
    "            If None, initialize an array of zeros.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[y, h]\n",
    "            y: mygrad.Tensor, shape=(T, K)\n",
    "                The final classification scores for each RNN step\n",
    "            h: mygrad.Tensor, shape=(T, D)\n",
    "                The hidden states computed at each RNN step, excluding the initial state h_0\n",
    "        \"\"\"\n",
    "        # Initialize the hidden state h_{t=0} as zeros if an\n",
    "        # initial hidden state is not provided as an argument.\n",
    "        #\n",
    "        # You will want to loop over each x_t to compute the\n",
    "        # corresponding h_t, then store each h_t in a list.\n",
    "        # You do not want to store the initial state h_{t=0}.\n",
    "        #\n",
    "        # You can use `mg.concatenate(list_of_h, axis=0)` to\n",
    "        # create a shape-(T, K) tensor of hidden-descriptors.\n",
    "        #\n",
    "        # A standard for-loop is appropriate here. Be mindful of what the shape \n",
    "        # of x_t should be versus the shape of the item that it produced by the\n",
    "        # for-loop.\n",
    "        #\n",
    "        # Note that you can do a for-loop over a mygrad-tensor and it will\n",
    "        # produce sub-tensors that are tracked by the computational graph.\n",
    "        # I.e. mygrad will be able to still \"backprop\" through your for-loop!\n",
    "        \n",
    "        # STUDENT CODE: \n",
    "        \n",
    "        h_t = np.zeros((1,self.fc_h2h.weight.shape[0]), dtype = np.float32)\n",
    "        h = [] # we do not need to store the initial state, as we do not return it/use it to compute y\n",
    "        \n",
    "        for x_t in x:\n",
    "            # `x_t[np.newaxis]` simply reshapes `x_t`: (C,) -> (1, C)\n",
    "            #\n",
    "            # h_t: shape-(1, D) hidden descriptor\n",
    "            h_t = relu(self.fc_x2h(x_t[np.newaxis]) + self.fc_h2h(h_t))\n",
    "            h.append(h_t)\n",
    "\n",
    "            \n",
    "        \n",
    "        # shape-(T, D) collection of T descriptors (each shape-(D,))\n",
    "        all_h = mg.concatenate(h, axis=0)\n",
    "        \n",
    "        \n",
    "        # `all_y` is:\n",
    "        # a shape-(T, K) collection of T \"prediction scores\", one produced\n",
    "        # in association with each of the T hidden descriptors.\n",
    "        #\n",
    "        # We will only be making use of `all_y[-1:]` for our prediction\n",
    "        # in our notebook; this is the shape-(1, K) vector associated with y_T\n",
    "        all_y = self.fc_h2y(all_h)\n",
    "        return all_y,all_h\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        \"\"\" A convenience function for getting all the parameters of our model.\n",
    "        \n",
    "        This can be accessed as an attribute, via `model.parameters` \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[Tensor, ...]\n",
    "            A tuple containing all of the learnable parameters for our model\n",
    "        \"\"\"\n",
    "        return self.fc_x2h.parameters + self.fc_h2h.parameters + self.fc_h2y.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1579160",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
